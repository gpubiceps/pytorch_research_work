{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1,2,3],[4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2621, 0.3873, 0.4846],\n",
       "        [0.7841, 0.0799, 0.1073]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.rand([2,3])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2.], requires_grad=True)\n",
      "tensor([4., 6.]) <- gradient\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(\n",
    "    [1.,  2.], requires_grad=True)\n",
    "\n",
    "print(x)\n",
    "\n",
    "function = ((x+1)**2).sum()\n",
    "\n",
    "function.backward()\n",
    "\n",
    "print(x.grad, '<- gradient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SumBackward0 at 0x7c7ccf8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_parabola(variable):\n",
    "    return ((variable + 1) ** 3).sum()\n",
    "\n",
    "def make_gradient_step(function, variable):\n",
    "    function_result = function(variable)\n",
    "    function_result.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "x = torch.tensor(\n",
    "    [2.,  8.], requires_grad=True)\n",
    "optimizer = torch.optim.SGD([x], lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.7300, 5.5700])\n"
     ]
    }
   ],
   "source": [
    "make_gradient_step(function_parabola, x)\n",
    "print(x.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_history = []\n",
    "fn_history = []\n",
    "for i in range(1500):\n",
    "    var_history.append(x.data.numpy().copy())\n",
    "    fn_history.append(function_parabola(x).data.cpu().numpy().copy())\n",
    "    make_gradient_step(function_parabola, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_contours(objective,\n",
    "                  x_lims=[-10.0, 10.0], \n",
    "                  y_lims=[-10.0, 10.0],\n",
    "                  x_ticks=100,\n",
    "                  y_ticks=100):\n",
    "    x_step = (x_lims[1] - x_lims[0]) / x_ticks\n",
    "    y_step = (y_lims[1] - y_lims[0]) / y_ticks\n",
    "    X, Y = np.mgrid[x_lims[0]:x_lims[1]:x_step, y_lims[0]:y_lims[1]:y_step]\n",
    "    res = []\n",
    "    for x_index in range(X.shape[0]):\n",
    "        res.append([])\n",
    "        for y_index in range(X.shape[1]):\n",
    "            x_val = X[x_index, y_index]\n",
    "            y_val = Y[x_index, y_index]\n",
    "            res[-1].append(objective(np.array([[x_val, y_val]]).T))\n",
    "    res = np.array(res)\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.contour(X, Y, res, 100)\n",
    "    plt.xlabel('$x_1$')\n",
    "    plt.ylabel('$x_2$')\n",
    "    \n",
    "show_contours(function_parabola)\n",
    "plt.scatter(np.array(var_history)[:,0], np.array(var_history)[:,1], s=10, c='r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   4,  16,  36,  64, 361])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([i ** 2 for i in range(20)])\n",
    "a[[0,2,4,6,8,19]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.zeros([6000, 28, 28], dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6000, 28, 28])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784, 6000])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape(-1,6000).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9920512it [00:06, 1436174.84it/s]                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST\\raw\\train-images-idx3-ubyte.gz to ./MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32768it [00:00, 69715.15it/s]                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST\\raw\\train-labels-idx1-ubyte.gz to ./MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1654784it [00:03, 496605.46it/s]                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8192it [00:00, 25518.80it/s]                                                   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./MNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "MNIST_train = torchvision.datasets.MNIST('./', download=True, train=True)\n",
    "MNIST_test = torchvision.datasets.MNIST('./', download=True, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Games\\Anaconda\\lib\\site-packages\\torchvision\\datasets\\mnist.py:53: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "C:\\Games\\Anaconda\\lib\\site-packages\\torchvision\\datasets\\mnist.py:43: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n",
      "C:\\Games\\Anaconda\\lib\\site-packages\\torchvision\\datasets\\mnist.py:58: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "C:\\Games\\Anaconda\\lib\\site-packages\\torchvision\\datasets\\mnist.py:48: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "X_train = MNIST_train.train_data\n",
    "y_train = MNIST_train.train_labels\n",
    "X_test = MNIST_test.test_data\n",
    "y_test = MNIST_test.test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_train[0, :, :])\n",
    "plt.show()\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.unsqueeze(1).float()\n",
    "X_test = X_test.unsqueeze(1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 1, 28, 28])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv2d(\n",
    "            in_channels=1, out_channels=6, kernel_size=5, padding=2)\n",
    "        self.act1  = torch.nn.Tanh()\n",
    "        self.pool1 = torch.nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "       \n",
    "        self.conv2 = torch.nn.Conv2d(\n",
    "            in_channels=6, out_channels=16, kernel_size=5, padding=0)\n",
    "        self.act2  = torch.nn.Tanh()\n",
    "        self.pool2 = torch.nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1   = torch.nn.Linear(5 * 5 * 16, 120)\n",
    "        self.act3  = torch.nn.Tanh()\n",
    "        \n",
    "        self.fc2   = torch.nn.Linear(120, 84)\n",
    "        self.act4  = torch.nn.Tanh()\n",
    "        \n",
    "        self.fc3   = torch.nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.act2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = x.view(x.size(0), x.size(1) * x.size(2) * x.size(3))\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.act3(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.act4(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "lenet5 = LeNet5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "lenet5 = lenet5.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(lenet5.parameters(), lr=1.0e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9763)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-292baea311d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mloss_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mloss_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Games\\Anaconda\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \"\"\"\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Games\\Anaconda\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "test_accuracy_history = []\n",
    "test_loss_history = []\n",
    "\n",
    "X_test = X_test.to(device)\n",
    "y_test = y_test.to(device)\n",
    "\n",
    "for epoch in range(10000):\n",
    "    order = np.random.permutation(len(X_train))\n",
    "    for start_index in range(0, len(X_train), batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        batch_indexes = order[start_index:start_index+batch_size]\n",
    "        \n",
    "        X_batch = X_train[batch_indexes].to(device)\n",
    "        y_batch = y_train[batch_indexes].to(device)\n",
    "        \n",
    "        preds = lenet5.forward(X_batch) \n",
    "        \n",
    "        loss_value = loss(preds, y_batch)\n",
    "        loss_value.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    test_preds = lenet5.forward(X_test)\n",
    "    test_loss_history.append(loss(test_preds, y_test).data.cpu())\n",
    "    \n",
    "    accuracy = (test_preds.argmax(dim=1) == y_test).float().mean().data.cpu()\n",
    "    test_accuracy_history.append(accuracy)\n",
    "    \n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5557,  0.3994,  1.2483,  ...,  9.5424, -0.7687,  1.1769],\n",
       "        [ 0.3980,  1.1006,  8.8365,  ..., -2.0143,  1.6916, -3.8993],\n",
       "        [-1.2097,  9.8840, -0.4177,  ...,  1.1958,  0.7212, -1.1686],\n",
       "        ...,\n",
       "        [-2.5091,  0.1988, -1.8570,  ...,  1.6646,  1.0125,  1.5692],\n",
       "        [-0.7997, -1.8384, -4.3044,  ..., -4.4996,  2.0715, -0.0269],\n",
       "        [ 1.1983, -2.4012, -0.6953,  ..., -4.9775, -1.1261, -2.4635]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenet5.forward(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0xfa12748>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(test_accuracy_history)\n",
    "plt.plot(test_loss_history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
